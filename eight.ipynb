{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "2 stage modelling:redifining imu"
      ],
      "metadata": {
        "id": "ece_PKJQsb_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imu_data(emotion):\n",
        "    if emotion == 0:   # Neutral\n",
        "        ax, ay, az = np.random.uniform(-0.5, 0.5, 3)\n",
        "        gx, gy, gz = np.random.uniform(-5, 5, 3)\n",
        "\n",
        "    elif emotion == 1: # Happy (light motion)\n",
        "        ax, ay, az = np.random.uniform(-1, 1, 3)\n",
        "        gx, gy, gz = np.random.uniform(-20, 20, 3)\n",
        "\n",
        "    else:              # Angry (aggressive motion)\n",
        "        ax, ay, az = np.random.uniform(-3, 3, 3)\n",
        "        gx, gy, gz = np.random.uniform(-80, 80, 3)\n",
        "    return [ax, ay, az, gx, gy, gz]\n",
        "\n",
        "# Also redefine gesture_map to ensure it matches the trained model (4 classes)\n",
        "gesture_map = {\n",
        "    0: \"Open Hand\",\n",
        "    1: \"Fist\",\n",
        "    2: \"Pointing\",\n",
        "    3: \"Pinch\" # Added for 4th class\n",
        "}\n",
        "\n",
        "# Example real-time input\n",
        "flex_angles_input = [10, 15, 80, 85, 80] # Example for 'Pointing' gesture\n",
        "pressure_input = [70, 65, 30, 90] # Example for 'Press Object' scenario\n",
        "emotion_type_for_imu = 2 # Example: Angry motion\n",
        "\n",
        "# Convert raw sensor data to voltages/readings\n",
        "current_flex_vals = [flex_voltage(a) for a in flex_angles_input]\n",
        "current_press_vals = [pressure_voltage(p) for p in pressure_input]\n",
        "current_imu_vals = imu_data(emotion_type_for_imu) # returns [ax, ay, az, gx, gy, gz]\n",
        "\n",
        "# Calculate engineered features for this single instance\n",
        "# For a single timestep, Gesture_Speed is interpreted as variance across flex sensors.\n",
        "gesture_speed_feature = np.var(current_flex_vals)\n",
        "pressure_variance_feature = np.var(current_press_vals)\n",
        "motion_magnitude_feature = np.sqrt(current_imu_vals[0]**2 + current_imu_vals[1]**2 + current_imu_vals[2]**2)\n",
        "\n",
        "# Prepare input for gesture model (LSTM)\n",
        "# The LSTM was trained on (samples, 1, features)\n",
        "sensor_input = np.array([[[gesture_speed_feature, pressure_variance_feature, motion_magnitude_feature]]])\n",
        "gesture_probs = model_gesture.predict(sensor_input)\n",
        "gesture_id = np.argmax(gesture_probs)\n",
        "\n",
        "gesture_text = gesture_map[gesture_id]\n",
        "\n",
        "# Gesture intensity (confidence)\n",
        "gesture_intensity = np.max(gesture_probs)\n",
        "\n",
        "# Stage 2 Prediction\n",
        "# Prepare input for emotion model (SVM)\n",
        "# SVM was trained on (samples, features) and scaled.\n",
        "# The original Xe_train features were 'Gesture_Speed', 'Pressure_Variance', 'Motion_Magnitude'\n",
        "emotion_input_features = np.array([[gesture_speed_feature, pressure_variance_feature, motion_magnitude_feature]])\n",
        "emotion_input_scaled = scaler.transform(emotion_input_features) # Use the scaler saved from the emotion model training\n",
        "emotion_id = emotion_model.predict(emotion_input_scaled)[0]\n",
        "emotion = emotion_map[emotion_id]\n",
        "\n",
        "print(\"Predicted Gesture:\", gesture_text, \"| Emotion:\", emotion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzhmQsNhsgWO",
        "outputId": "b655c2d4-31d3-4939-d040-2f65aa1f946f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Gesture: Pointing | Emotion: Angry\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1WS-UPqQtPHs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}